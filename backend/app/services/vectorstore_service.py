"""
å‘é‡å­˜å‚¨æœåŠ¡ - åŸºäºChromaDB
"""
import chromadb
from chromadb.config import Settings as ChromaSettings
import numpy as np
from typing import List, Tuple, Dict, Optional
from pathlib import Path
from app.config import settings
from app.models import EmbeddingProvider
from app.services.embedding_service import EmbeddingService
from app.logger import get_logger

logger = get_logger("rag-chat.vectorstore")


class VectorStoreService:
    """
    å‘é‡å­˜å‚¨æœåŠ¡
    
    ç‰¹æ€§ï¼š
    - ä½¿ç”¨ChromaDBæŒä¹…åŒ–å­˜å‚¨
    - ä½¿ç”¨ä½™å¼¦è·ç¦»ï¼ˆcosineï¼‰è¿›è¡Œç›¸ä¼¼åº¦è®¡ç®—
    - æ”¯æŒæŒ‰æ–‡æ¡£IDè¿‡æ»¤
    - ä½¿ç”¨HNSWç´¢å¼•åŠ é€Ÿæ£€ç´¢
    """
    
    COLLECTION_NAME = "documents"
    
    def __init__(self):
        """åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯"""
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        chroma_dir = Path(settings.CHROMA_DIR)
        chroma_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=str(chroma_dir),
            settings=ChromaSettings(
                anonymized_telemetry=False,
                allow_reset=False
            )
        )
        
        self.embedding_service = EmbeddingService()
        
        logger.info(f"ğŸ“ ChromaDBåˆå§‹åŒ–å®Œæˆ: {chroma_dir}")
    
    def get_or_create_collection(self):
        """
        è·å–æˆ–åˆ›å»ºcollection
        
        å…³é”®é…ç½®ï¼š
        - hnsw:space = cosineï¼šä½¿ç”¨ä½™å¼¦è·ç¦»ï¼ˆå½’ä¸€åŒ–ï¼Œåªçœ‹æ–¹å‘ï¼‰
        - hnsw:construction_ef = 100ï¼šæ„å»ºç´¢å¼•æ—¶çš„æœç´¢èŒƒå›´
        - hnsw:M = 16ï¼šHNSWå›¾çš„è¿æ¥æ•°
        """
        return self.client.get_or_create_collection(
            name=self.COLLECTION_NAME,
            metadata={
                "hnsw:space": "cosine",  # ğŸ”¥ ä½¿ç”¨ä½™å¼¦è·ç¦»ï¼Œé€‚åˆæ–‡æœ¬è¯­ä¹‰æ£€ç´¢
                "hnsw:construction_ef": 100,
                "hnsw:M": 16
            }
        )
    
    async def add_documents(
        self,
        embedding_provider: EmbeddingProvider,
        document_id: int,
        chunks: List[str],
        metadatas: List[Dict]
    ):
        """
        æ·»åŠ æ–‡æ¡£å‘é‡åˆ°å‘é‡åº“
        
        Args:
            embedding_provider: Embeddingé…ç½®
            document_id: æ–‡æ¡£ID
            chunks: æ–‡æœ¬åˆ†å—åˆ—è¡¨
            metadatas: å…ƒæ•°æ®åˆ—è¡¨ï¼ˆéœ€åŒ…å«document_id, filename, chunk_indexï¼‰
        """
        if not chunks:
            raise ValueError("chunksä¸èƒ½ä¸ºç©º")
        
        logger.info(f"ğŸ”¢ å¼€å§‹å‘é‡åŒ–: {len(chunks)} ä¸ªåˆ†å—")
        
        # 1. ç”Ÿæˆå‘é‡
        embeddings = await self.embedding_service.get_embeddings(
            embedding_provider, chunks
        )
        
        logger.info(f"âœ… å‘é‡åŒ–å®Œæˆ: shape={embeddings.shape}")
        
        # 2. æ·»åŠ åˆ°ChromaDB
        collection = self.get_or_create_collection()
        
        # ç”Ÿæˆå”¯ä¸€ID
        ids = [f"doc_{document_id}_chunk_{i}" for i in range(len(chunks))]
        
        # æ‰¹é‡æ·»åŠ 
        collection.add(
            ids=ids,
            embeddings=embeddings.tolist(),
            documents=chunks,
            metadatas=metadatas
        )
        
        logger.info(f"ğŸ’¾ å·²æ·»åŠ  {len(chunks)} ä¸ªå‘é‡åˆ°ChromaDB")
    
    async def similarity_search_with_score(
        self,
        embedding_provider: EmbeddingProvider,
        query: str,
        k: int = 5,
        document_ids: Optional[List[int]] = None
    ) -> List[Tuple[object, float]]:
        """
        å‘é‡ç›¸ä¼¼åº¦æ£€ç´¢
        
        Args:
            embedding_provider: Embeddingé…ç½®
            query: æŸ¥è¯¢æ–‡æœ¬
            k: è¿”å›top-kä¸ªç»“æœ
            document_ids: å¯é€‰ï¼Œåªåœ¨æŒ‡å®šæ–‡æ¡£ä¸­æ£€ç´¢
            
        Returns:
            List[(Documentå¯¹è±¡, ç›¸ä¼¼åº¦åˆ†æ•°)]
            - Documentå¯¹è±¡åŒ…å«ï¼špage_content, metadata
            - ç›¸ä¼¼åº¦åˆ†æ•°ï¼š0-1ä¹‹é—´ï¼Œè¶Šå¤§è¶Šç›¸ä¼¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        """
        # 1. æŸ¥è¯¢å‘é‡åŒ–
        logger.debug(f"ğŸ” å‘é‡åŒ–æŸ¥è¯¢: {query[:50]}...")
        query_embedding = await self.embedding_service.get_embeddings(
            embedding_provider, [query]
        )
        
        # 2. æ„å»ºè¿‡æ»¤æ¡ä»¶
        where = None
        if document_ids:
            where = {"document_id": {"$in": document_ids}}
        
        # 3. æ£€ç´¢
        collection = self.get_or_create_collection()
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=k,
            where=where,
            include=["documents", "metadatas", "distances"]
        )
        
        # 4. è½¬æ¢ç»“æœ
        if not results["documents"] or not results["documents"][0]:
            logger.warning("âš ï¸  æœªæ£€ç´¢åˆ°ä»»ä½•ç»“æœ")
            return []
        
        chunks = results["documents"][0]
        distances = results["distances"][0]
        metadatas = results["metadatas"][0]
        
        # ğŸ”¥ ä½™å¼¦è·ç¦»è½¬ä½™å¼¦ç›¸ä¼¼åº¦ï¼šsimilarity = 1 - distance
        # ChromaDBçš„cosineè·ç¦»èŒƒå›´[0, 2]ï¼Œè½¬ä¸ºç›¸ä¼¼åº¦[1, -1]ï¼ˆé€šå¸¸åœ¨[0.5, 1]ï¼‰
        similarities = [1 - dist for dist in distances]
        
        # 5. æ„é€ Documentå¯¹è±¡ï¼ˆå…¼å®¹æ—§ä»£ç çš„langchainæ ¼å¼ï¼‰
        from langchain_core.documents import Document
        
        documents_with_scores = []
        for chunk, similarity, metadata in zip(chunks, similarities, metadatas):
            doc = Document(
                page_content=chunk,
                metadata=metadata
            )
            documents_with_scores.append((doc, similarity))
        
        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: è¿”å› {len(documents_with_scores)} ä¸ªç»“æœ")
        
        return documents_with_scores
    
    async def delete_documents(self, document_id: int):
        """
        åˆ é™¤æ–‡æ¡£çš„æ‰€æœ‰å‘é‡
        
        Args:
            document_id: æ–‡æ¡£ID
        """
        collection = self.get_or_create_collection()
        
        # æŒ‰metadataè¿‡æ»¤åˆ é™¤
        collection.delete(
            where={"document_id": document_id}
        )
        
        logger.info(f"ğŸ—‘ï¸  å·²åˆ é™¤æ–‡æ¡£ {document_id} çš„æ‰€æœ‰å‘é‡")
    
    def get_collection_stats(self) -> dict:
        """
        è·å–å‘é‡åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            {
                "total_vectors": int,
                "collection_name": str
            }
        """
        try:
            collection = self.get_or_create_collection()
            count = collection.count()
            
            return {
                "total_vectors": count,
                "collection_name": self.COLLECTION_NAME
            }
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {
                "total_vectors": 0,
                "collection_name": self.COLLECTION_NAME
            }
    
    def reset_collection(self):
        """
        æ¸…ç©ºå¹¶é‡å»ºcollection
        
        âš ï¸  å±é™©æ“ä½œï¼šä¼šåˆ é™¤æ‰€æœ‰å‘é‡æ•°æ®ï¼
        ç”¨äºï¼š
        - åˆ‡æ¢è·ç¦»åº¦é‡æ–¹å¼
        - æ¸…ç©ºæµ‹è¯•æ•°æ®
        """
        try:
            self.client.delete_collection(self.COLLECTION_NAME)
            logger.warning(f"ğŸ—‘ï¸  å·²åˆ é™¤collection: {self.COLLECTION_NAME}")
        except Exception:
            pass
        
        collection = self.get_or_create_collection()
        logger.info(f"âœ… å·²é‡å»ºcollection: {self.COLLECTION_NAME}")
        
        return collection


