"""
èŠå¤©æœåŠ¡ - RAGé—®ç­”
"""
import json
import time
from typing import AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from app.models import (
    Chatbot,
    Conversation,
    Message,
    LLMProvider,
    EmbeddingProvider,
)
from app.services.llm_service import LLMService
from app.services.vectorstore_service import VectorStoreService
from app.services.chat_log_service import ChatLogService
from app.logger import get_logger

logger = get_logger("rag-chat.chat")


class ChatService:
    """èŠå¤©æœåŠ¡"""
    
    def __init__(self):
        self.llm_service = LLMService()
        self.vectorstore_service = VectorStoreService()
    
    async def get_default_embedding_provider(self, db: AsyncSession) -> EmbeddingProvider | None:
        """è·å–é»˜è®¤Embedding Provider"""
        result = await db.execute(
            select(EmbeddingProvider)
            .where(EmbeddingProvider.is_default == True, EmbeddingProvider.is_active == True)
        )
        return result.scalar_one_or_none()
    
    async def _rewrite_query(
        self,
        conversation: Conversation,
        user_message: str,
        rewrite_provider: LLMProvider,
        rewrite_model: str | None
    ) -> str | None:
        """
        ä½¿ç”¨LLMé‡å†™æŸ¥è¯¢ï¼Œä½¿å…¶æ›´é€‚åˆæ£€ç´¢
        """
        # æ„å»ºæœ€è¿‘2-3è½®å¯¹è¯å†å²
        recent_messages = conversation.messages[-6:]  # æœ€å¤š3è½®å¯¹è¯ï¼ˆ6æ¡æ¶ˆæ¯ï¼‰
        
        history_text = ""
        for msg in recent_messages:
            role_name = "ç”¨æˆ·" if msg.role == "user" else "åŠ©æ‰‹"
            history_text += f"{role_name}: {msg.content}\n"
        
        rewrite_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæŸ¥è¯¢é‡å†™åŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·æœ€æ–°é—®é¢˜æ˜¯å¦éœ€è¦ä¾èµ–å¯¹è¯å†å²æ¥ç†è§£ï¼Œç„¶åè¿›è¡Œé€‚å½“å¤„ç†ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
- å¦‚æœé—®é¢˜åŒ…å«æŒ‡ä»£è¯ï¼ˆå¦‚"å®ƒ"ã€"è¿™ä¸ª"ã€"ä»–çš„"ç­‰ï¼‰æˆ–çœç•¥ä¸»è¯­ï¼Œéœ€è¦ä»å†å²ä¸­è¡¥å……
- å¦‚æœé—®é¢˜æœ¬èº«å·²ç»å®Œæ•´ç‹¬ç«‹ã€ä¸ä¾èµ–ä¸Šä¸‹æ–‡å°±èƒ½ç†è§£ï¼Œåˆ™ä¿æŒåŸæ ·æˆ–ä»…åšè½»å¾®ä¼˜åŒ–

è¦æ±‚ï¼š
1. åªæœ‰åœ¨é—®é¢˜ç¡®å®ä¾èµ–ä¸Šä¸‹æ–‡æ—¶æ‰è¡¥å……ä¿¡æ¯
2. ä¸è¦å¼ºè¡Œå°†å†å²è¯é¢˜æ•´åˆåˆ°ç‹¬ç«‹çš„æ–°é—®é¢˜ä¸­
3. è§£å†³çœŸæ­£çš„æŒ‡ä»£é—®é¢˜ï¼ˆä»£è¯â†’å…·ä½“åè¯ï¼‰
4. ä¿æŒæŸ¥è¯¢ç®€æ´æ˜ç¡®ï¼Œé€‚åˆæ£€ç´¢
5. åªè¾“å‡ºæ”¹å†™åçš„æŸ¥è¯¢ï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Š

ç¤ºä¾‹ï¼š
- å†å²è®¨è®º"Claude 4.5 Opus" â†’ ç”¨æˆ·é—®"å®ƒæ”¯æŒå¤šæ¨¡æ€å—" â†’ é‡å†™ä¸º"Claude 4.5 Opusæ”¯æŒå¤šæ¨¡æ€å—"ï¼ˆè¡¥å……æŒ‡ä»£ï¼‰
- å†å²è®¨è®º"Claude 4.5 Opus" â†’ ç”¨æˆ·é—®"æœ‰å“ªäº›è¢«åºŸå¼ƒäº†çš„æ¨¡å‹" â†’ ä¿æŒ"æœ‰å“ªäº›è¢«åºŸå¼ƒäº†çš„æ¨¡å‹"ï¼ˆç‹¬ç«‹é—®é¢˜ï¼Œä¸è¡¥å……ï¼‰

{f"å¯¹è¯å†å²ï¼š{chr(10)}{history_text}" if history_text else ""}
ç”¨æˆ·æœ€æ–°é—®é¢˜ï¼š{user_message}

æ”¹å†™åçš„æŸ¥è¯¢ï¼š"""

        try:
            response = await self.llm_service.chat(
                provider=rewrite_provider,
                messages=[{"role": "user", "content": rewrite_prompt}],
                model=rewrite_model,
                temperature=0.1,  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§
                max_tokens=200   # æŸ¥è¯¢ä¸éœ€è¦å¤ªé•¿
            )
            
            # æ¸…ç†å“åº”
            rewritten = response.strip()
            # ç§»é™¤å¯èƒ½çš„å¼•å·
            if rewritten.startswith('"') and rewritten.endswith('"'):
                rewritten = rewritten[1:-1]
            if rewritten.startswith("'") and rewritten.endswith("'"):
                rewritten = rewritten[1:-1]
            
            return rewritten if rewritten else None
        except Exception as e:
            logger.error(f"æŸ¥è¯¢é‡å†™å¤±è´¥: {e}")
            return None
    
    async def chat(
        self,
        db: AsyncSession,
        conversation: Conversation,
        user_message: str,
        stream: bool = True
    ) -> AsyncGenerator[str, None] | tuple[str, list[dict]]:
        """
        èŠå¤©ï¼ˆæ”¯æŒRAGæ£€ç´¢ï¼‰
        """
        start_time = time.time()
        chatbot = conversation.chatbot
        
        logger.info(f"ğŸ’¬ æ”¶åˆ°èŠå¤©è¯·æ±‚: Bot={chatbot.name}, ä¼šè¯ID={conversation.id}")
        logger.info(f"   ç”¨æˆ·: {user_message[:50]}{'...' if len(user_message) > 50 else ''}")
        
        # è·å–LLM Provider
        if not chatbot.llm_provider:
            logger.error("âŒ Chatbotæœªé…ç½®LLM Provider")
            raise ValueError("Chatbot has no LLM provider configured")
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        
        # ç³»ç»Ÿæç¤º
        system_prompt = chatbot.system_prompt or "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"
        
        # æ—¥å¿—ç›¸å…³å˜é‡
        rag_start_time = None
        rag_time_ms = None
        sources = []
        use_rag = chatbot.use_knowledge_base
        
        # æŸ¥è¯¢é‡å†™ç›¸å…³å˜é‡
        use_query_rewrite = bool(chatbot.use_query_rewrite and chatbot.rewrite_provider)
        rewrite_time_ms = None
        rewritten_query = None
        rag_query = user_message  # é»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢
        
        # ğŸ”„ å¦‚æœå¯ç”¨æŸ¥è¯¢é‡å†™ï¼Œå…ˆé‡å†™æŸ¥è¯¢
        if use_query_rewrite and use_rag:
            rewrite_start_time = time.time()
            try:
                rewritten_query = await self._rewrite_query(
                    conversation=conversation,
                    user_message=user_message,
                    rewrite_provider=chatbot.rewrite_provider,
                    rewrite_model=chatbot.rewrite_model
                )
                rewrite_time_ms = int((time.time() - rewrite_start_time) * 1000)
                
                if rewritten_query and rewritten_query != user_message:
                    rag_query = rewritten_query
                    logger.info(f"âœï¸ æŸ¥è¯¢é‡å†™å®Œæˆ ({rewrite_time_ms}ms)")
                    logger.info(f"   åŸå§‹: {user_message[:50]}{'...' if len(user_message) > 50 else ''}")
                    logger.info(f"   é‡å†™: {rewritten_query[:50]}{'...' if len(rewritten_query) > 50 else ''}")
                else:
                    logger.info(f"âœï¸ æŸ¥è¯¢æ— éœ€é‡å†™ ({rewrite_time_ms}ms)")
                    rewritten_query = None  # å¦‚æœæ²¡æœ‰å˜åŒ–ï¼Œä¸è®°å½•
            except Exception as e:
                rewrite_time_ms = int((time.time() - rewrite_start_time) * 1000)
                logger.warning(f"âš ï¸ æŸ¥è¯¢é‡å†™å¤±è´¥ ({rewrite_time_ms}ms): {e}")
                # é‡å†™å¤±è´¥ä¸å½±å“åç»­æµç¨‹ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢
        
        # ğŸ”¥ å¦‚æœå¯ç”¨çŸ¥è¯†åº“ï¼Œè¿›è¡ŒRAGæ£€ç´¢
        if use_rag:
            embedding_provider = await self.get_default_embedding_provider(db)
            if embedding_provider:
                logger.info(f"ğŸ” å¼€å§‹RAGæ£€ç´¢... (Embedding: {embedding_provider.name})")
                rag_start_time = time.time()
                
                try:
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ£€ç´¢ï¼ˆä½¿ç”¨é‡å†™åçš„æŸ¥è¯¢æˆ–åŸå§‹æŸ¥è¯¢ï¼‰
                    docs_with_scores = await self.vectorstore_service.similarity_search_with_score(
                        embedding_provider=embedding_provider,
                        query=rag_query,  # ä½¿ç”¨å¯èƒ½é‡å†™è¿‡çš„æŸ¥è¯¢
                        k=chatbot.top_k,
                    )
                    
                    rag_time_ms = int((time.time() - rag_start_time) * 1000)
                    logger.info(f"âœ… RAGæ£€ç´¢å®Œæˆ: æ‰¾åˆ° {len(docs_with_scores)} ä¸ªç›¸å…³æ–‡æ¡£ ({rag_time_ms}ms)")
                    
                    if docs_with_scores:
                        # æ„å»ºä¸Šä¸‹æ–‡
                        context_parts = []
                        for doc, score in docs_with_scores:
                            context_parts.append(doc.page_content)
                            sources.append(
                                {
                                    "document_id": doc.metadata.get("document_id"),
                                    "filename": doc.metadata.get("filename"),
                                    "chunk_index": doc.metadata.get("chunk_index"),
                                    "content": doc.page_content,  # ä¿å­˜å®Œæ•´å†…å®¹ï¼Œæ–¹ä¾¿æ ¡éªŒ
                                    "score": float(score),
                                }
                            )
                            logger.debug(
                                f"   - {doc.metadata.get('filename')} "
                                f"[chunk {doc.metadata.get('chunk_index')}]: "
                                f"score={score:.4f}"
                            )
                        
                        context = "\n\n---\n\n".join(context_parts)
                        system_prompt += (
                            "\n\nè¯·åŸºäºä»¥ä¸‹å‚è€ƒèµ„æ–™å›ç­”é—®é¢˜ã€‚å¦‚æœèµ„æ–™ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·å¦‚å®å‘ŠçŸ¥ã€‚\n\nå‚è€ƒèµ„æ–™ï¼š\n"
                            f"{context}"
                        )
                        
                        logger.info(f"ğŸ“š å·²æ„å»ºä¸Šä¸‹æ–‡: {len(context_parts)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
                    else:
                        logger.warning("âš ï¸  æœªæ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£")
                
                except Exception as e:
                    logger.error(f"âŒ RAGæ£€ç´¢å¤±è´¥: {e}", exc_info=True)
                    # RAGå¤±è´¥ä¸å½±å“å¯¹è¯ï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€LLM
            else:
                logger.warning("âš ï¸  æœªé…ç½®é»˜è®¤Embedding Providerï¼Œè·³è¿‡RAGæ£€ç´¢")
        
        messages.append({"role": "system", "content": system_prompt})
        
        # å†å²æ¶ˆæ¯ï¼ˆæœ€è¿‘10æ¡ï¼‰
        history_count = len(conversation.messages[-10:])
        if history_count > 0:
            logger.debug(f"ğŸ“œ åŠ è½½å†å²æ¶ˆæ¯: {history_count} æ¡")
        for msg in conversation.messages[-10:]:
            messages.append({"role": msg.role, "content": msg.content})
        
        # å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({"role": "user", "content": user_message})
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        user_msg = Message(
            conversation_id=conversation.id,
            role="user",
            content=user_message
        )
        db.add(user_msg)
        await db.flush()
        
        logger.info(f"ğŸ¤– è°ƒç”¨LLM: {chatbot.llm_provider.name} / {chatbot.model}")
        
        if stream:
            # æµå¼å“åº”
            async def generate():
                llm_start_time = time.time()
                full_response = ""
                error_occurred = False
                error_message = None
                
                try:
                    async for chunk in self.llm_service.chat_stream(
                        provider=chatbot.llm_provider,
                        messages=messages,
                        model=chatbot.model,
                        temperature=chatbot.temperature,
                        max_tokens=chatbot.max_tokens
                    ):
                        full_response += chunk
                        yield chunk
                except Exception as e:
                    error_occurred = True
                    error_message = str(e)
                    logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                    raise
                finally:
                    llm_time_ms = int((time.time() - llm_start_time) * 1000)
                    total_time_ms = int((time.time() - start_time) * 1000)
                    
                    # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                    assistant_msg_id = None
                    if full_response:
                        assistant_msg = Message(
                            conversation_id=conversation.id,
                            role="assistant",
                            content=full_response,
                            sources=json.dumps(sources) if sources else None
                        )
                        db.add(assistant_msg)
                        await db.flush()
                        assistant_msg_id = assistant_msg.id
                    
                    # æ›´æ–°ä¼šè¯æ ‡é¢˜ï¼ˆå¦‚æœæ˜¯ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼‰
                    if len(conversation.messages) <= 2:
                        conversation.title = user_message[:50]
                        await db.flush()
                    
                    # è®°å½•æ—¥å¿—ï¼ˆå…³è”åŠ©æ‰‹æ¶ˆæ¯IDï¼‰
                    await ChatLogService.create_log(
                        db=db,
                        conversation_id=conversation.id,
                        chatbot_id=chatbot.id,
                        llm_provider_id=chatbot.llm_provider_id,
                        llm_provider_name=chatbot.llm_provider.name if chatbot.llm_provider else None,
                        model=chatbot.model,
                        input_text=user_message,
                        output_text=full_response if full_response else None,
                        system_prompt=system_prompt,
                        use_query_rewrite=use_query_rewrite,
                        rewrite_time_ms=rewrite_time_ms,
                        rewritten_query=rewritten_query,
                        use_rag=use_rag,
                        rag_query_time_ms=rag_time_ms,
                        rag_results_count=len(sources) if sources else None,
                        rag_results=sources if sources else None,
                        total_time_ms=total_time_ms,
                        llm_time_ms=llm_time_ms,
                        status="error" if error_occurred else "success",
                        error_message=error_message,
                        message_id=assistant_msg_id
                    )
                    await db.flush()
                    
                    if not error_occurred:
                        response_preview = full_response[:50] + "..." if len(full_response) > 50 else full_response
                        logger.info(f"âœ… å›å¤å®Œæˆ: {response_preview}")
                        logger.info(f"   è€—æ—¶: æ€»è®¡={total_time_ms}ms, LLM={llm_time_ms}ms, RAG={rag_time_ms or 0}ms, é‡å†™={rewrite_time_ms or 0}ms")
            
            return generate()
        else:
            # éæµå¼å“åº”
            llm_start_time = time.time()
            error_occurred = False
            error_message = None
            response = ""
            
            try:
                response = await self.llm_service.chat(
                    provider=chatbot.llm_provider,
                    messages=messages,
                    model=chatbot.model,
                    temperature=chatbot.temperature,
                    max_tokens=chatbot.max_tokens
                )
            except Exception as e:
                error_occurred = True
                error_message = str(e)
                logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                raise
            finally:
                llm_time_ms = int((time.time() - llm_start_time) * 1000)
                total_time_ms = int((time.time() - start_time) * 1000)
            
            # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
            assistant_msg = Message(
                conversation_id=conversation.id,
                role="assistant",
                content=response,
                sources=json.dumps(sources) if sources else None
            )
            db.add(assistant_msg)
            await db.flush()
            
            # è®°å½•æ—¥å¿—ï¼ˆå…³è”åŠ©æ‰‹æ¶ˆæ¯IDï¼‰
            await ChatLogService.create_log(
                db=db,
                conversation_id=conversation.id,
                chatbot_id=chatbot.id,
                llm_provider_id=chatbot.llm_provider_id,
                llm_provider_name=chatbot.llm_provider.name if chatbot.llm_provider else None,
                model=chatbot.model,
                input_text=user_message,
                output_text=response if response else None,
                system_prompt=system_prompt,
                use_query_rewrite=use_query_rewrite,
                rewrite_time_ms=rewrite_time_ms,
                rewritten_query=rewritten_query,
                use_rag=use_rag,
                rag_query_time_ms=rag_time_ms,
                rag_results_count=len(sources) if sources else None,
                rag_results=sources if sources else None,
                total_time_ms=total_time_ms,
                llm_time_ms=llm_time_ms,
                status="error" if error_occurred else "success",
                error_message=error_message,
                message_id=assistant_msg.id
            )
            
            # æ›´æ–°ä¼šè¯æ ‡é¢˜
            if len(conversation.messages) <= 2:
                conversation.title = user_message[:50]
                await db.flush()
            
            response_preview = response[:50] + "..." if len(response) > 50 else response
            logger.info(f"âœ… å›å¤å®Œæˆ: {response_preview}")
            logger.info(f"   è€—æ—¶: æ€»è®¡={total_time_ms}ms, LLM={llm_time_ms}ms, RAG={rag_time_ms or 0}ms, é‡å†™={rewrite_time_ms or 0}ms")
            
            return response, sources
