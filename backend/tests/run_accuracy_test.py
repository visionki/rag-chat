"""
RAG ç³»ç»Ÿå‡†ç¡®æ€§æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
    # è¿è¡Œæ£€ç´¢æµ‹è¯•
    python tests/run_accuracy_test.py --mode retrieval
    
    # è¿è¡Œå®Œæ•´æµ‹è¯•ï¼ˆæ£€ç´¢+ç­”æ¡ˆè´¨é‡ï¼‰
    python tests/run_accuracy_test.py --mode full
    
    # æŒ‡å®šè¾“å‡ºç›®å½•
    python tests/run_accuracy_test.py --output-dir ./test_results
"""
import asyncio
import argparse
import json
import sys
from pathlib import Path
from datetime import datetime

sys.path.insert(0, str(Path(__file__).parent.parent))

from app.database import async_session_maker
from app.services.chat_service import ChatService
from app.services.vectorstore_service import VectorStoreService
from app.models import Chatbot, EmbeddingProvider, Conversation
from sqlalchemy import select
from sqlalchemy.orm import selectinload

from metrics import RetrievalMetrics, AnswerQualityMetrics


def load_test_cases():
    """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
    test_file = Path(__file__).parent / "test_data" / "qa_test_set.json"
    with open(test_file, 'r', encoding='utf-8') as f:
        return json.load(f)["test_cases"]


async def run_retrieval_test(test_cases, vectorstore_service, embedding_provider):
    """è¿è¡Œæ£€ç´¢è´¨é‡æµ‹è¯•ï¼ˆåŸºäºå†…å®¹å…³é”®è¯åŒ¹é…ï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æ£€ç´¢è´¨é‡æµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n[{i}/{len(test_cases)}] {case['question']}")
        
        try:
            docs_with_scores = await vectorstore_service.similarity_search_with_score(
                embedding_provider=embedding_provider,
                query=case["question"],
                k=10
            )
            
            # è·å–æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹
            retrieved_contents = [doc.page_content for doc, _ in docs_with_scores[:5]]
            combined_content = "\n".join(retrieved_contents).lower()
            
            # æ£€æŸ¥å…³é”®è¯æ˜¯å¦å‡ºç°åœ¨æ£€ç´¢ç»“æœä¸­
            retrieval_keywords = case.get("retrieval_keywords", case.get("expected_keywords", []))
            keywords_found = sum(1 for kw in retrieval_keywords if kw.lower() in combined_content)
            keyword_coverage = keywords_found / len(retrieval_keywords) if retrieval_keywords else 0
            
            # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°ç»Ÿè®¡
            top_scores = [float(score) for _, score in docs_with_scores[:5]]
            avg_score = sum(top_scores) / len(top_scores) if top_scores else 0
            
            result = {
                "question": case["question"],
                "category": case.get("category", "unknown"),
                "difficulty": case.get("difficulty", "medium"),
                "keyword_coverage": keyword_coverage,
                "keywords_found": keywords_found,
                "keywords_total": len(retrieval_keywords),
                "avg_similarity": avg_score,
                "top_scores": top_scores[:3],
                "preview": retrieved_contents[0][:100] if retrieved_contents else ""
            }
            results.append(result)
            
            status = "âœ“" if keyword_coverage >= 0.6 else "âš "
            print(f"  {status} å…³é”®è¯è¦†ç›–: {keywords_found}/{len(retrieval_keywords)} ({keyword_coverage:.1%})")
            print(f"    å¹³å‡ç›¸ä¼¼åº¦: {avg_score:.3f}")
            
        except Exception as e:
            print(f"  âœ— é”™è¯¯: {e}")
            results.append({"question": case["question"], "error": str(e)})
    
    return _summarize_retrieval(results)


async def run_answer_test(test_cases, chat_service, chatbot, db):
    """è¿è¡Œç­”æ¡ˆè´¨é‡æµ‹è¯•"""
    print("\n" + "=" * 60)
    print("ğŸ“ ç­”æ¡ˆè´¨é‡æµ‹è¯•")
    print("=" * 60)
    
    metrics = AnswerQualityMetrics()
    results = []
    
    # åˆ›å»ºæµ‹è¯•ä¼šè¯
    conversation = Conversation(chatbot_id=chatbot.id, title="æµ‹è¯•ä¼šè¯")
    db.add(conversation)
    await db.commit()
    
    result = await db.execute(
        select(Conversation)
        .where(Conversation.id == conversation.id)
        .options(selectinload(Conversation.chatbot), selectinload(Conversation.messages))
    )
    conversation = result.scalar_one()
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n[{i}/{len(test_cases)}] {case['question']}")
        
        try:
            answer, _ = await chat_service.chat(
                db=db, conversation=conversation, user_message=case["question"], stream=False
            )
            
            result = {
                "question": case["question"],
                "answer": answer,
                "category": case["category"],
                "difficulty": case["difficulty"],
                "keyword_coverage": metrics.keyword_coverage(answer, case["expected_keywords"]),
                "length_score": metrics.answer_length_score(answer, 20, 500),
                "no_hallucination": metrics.no_hallucination_keywords(
                    answer, ["æŠ±æ­‰", "ä¸çŸ¥é“", "æ— æ³•å›ç­”", "æ²¡æœ‰ç›¸å…³ä¿¡æ¯"]
                )
            }
            results.append(result)
            
            print(f"  å…³é”®è¯è¦†ç›–: {result['keyword_coverage']:.3f}")
            print(f"  ç­”æ¡ˆé¢„è§ˆ: {answer[:80]}...")
            
        except Exception as e:
            print(f"  âœ— é”™è¯¯: {e}")
            results.append({"question": case["question"], "error": str(e)})
    
    return _summarize_answer(results)


def _summarize_retrieval(results):
    """æ±‡æ€»æ£€ç´¢æµ‹è¯•ç»“æœ"""
    valid = [r for r in results if "error" not in r]
    if not valid:
        return {"error": "æ— æœ‰æ•ˆç»“æœ"}
    
    avg_coverage = sum(r["keyword_coverage"] for r in valid) / len(valid)
    avg_similarity = sum(r["avg_similarity"] for r in valid) / len(valid)
    full_coverage_count = sum(1 for r in valid if r["keyword_coverage"] == 1.0)
    
    summary = {
        "avg_keyword_coverage": avg_coverage,
        "avg_similarity": avg_similarity,
        "full_coverage_rate": full_coverage_count / len(valid),
        "total": len(results),
        "successful": len(valid)
    }
    
    # è¯„ä¼°è´¨é‡
    if avg_coverage >= 0.8:
        quality = "ä¼˜ç§€ ğŸ‰"
    elif avg_coverage >= 0.6:
        quality = "è‰¯å¥½ âœ“"
    else:
        quality = "éœ€è¦æ”¹è¿› âš ï¸"
    
    print("\n" + "-" * 60)
    print(f"å¹³å‡å…³é”®è¯è¦†ç›–: {avg_coverage:.1%}")
    print(f"å®Œå…¨è¦†ç›–ç‡: {full_coverage_count}/{len(valid)} ({summary['full_coverage_rate']:.1%})")
    print(f"å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
    print(f"æ•´ä½“è´¨é‡: {quality}")
    print(f"æˆåŠŸ: {summary['successful']}/{summary['total']}")
    
    return {"summary": summary, "quality": quality, "details": results}


def _summarize_answer(results):
    """æ±‡æ€»ç­”æ¡ˆæµ‹è¯•ç»“æœ"""
    valid = [r for r in results if "error" not in r]
    if not valid:
        return {"error": "æ— æœ‰æ•ˆç»“æœ"}
    
    summary = {
        "avg_keyword_coverage": sum(r["keyword_coverage"] for r in valid) / len(valid),
        "avg_length_score": sum(r["length_score"] for r in valid) / len(valid),
        "hallucination_free_rate": sum(1 for r in valid if r["no_hallucination"]) / len(valid),
        "total": len(results),
        "successful": len(valid)
    }
    
    print("\n" + "-" * 60)
    print(f"å¹³å‡å…³é”®è¯è¦†ç›–: {summary['avg_keyword_coverage']:.3f}")
    print(f"æ— å¹»è§‰ç‡: {summary['hallucination_free_rate']:.3f}")
    print(f"æˆåŠŸ: {summary['successful']}/{summary['total']}")
    
    return {"summary": summary, "details": results}


async def run_tests(mode: str, output_dir: str):
    """è¿è¡Œæµ‹è¯•"""
    print("=" * 60)
    print(f"ğŸ¯ RAG ç³»ç»Ÿå‡†ç¡®æ€§æµ‹è¯• (æ¨¡å¼: {mode})")
    print("=" * 60)
    print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    test_cases = load_test_cases()
    print(f"åŠ è½½äº† {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    
    # è·å–é…ç½®
    async with async_session_maker() as db:
        result = await db.execute(
            select(EmbeddingProvider).where(EmbeddingProvider.is_default == True)
        )
        embedding_provider = result.scalar_one_or_none()
        
        if not embedding_provider:
            print("âŒ æœªæ‰¾åˆ°é»˜è®¤åµŒå…¥æä¾›å•†")
            return
        
        result = await db.execute(select(Chatbot).limit(1))
        chatbot = result.scalar_one_or_none()
        
        print(f"åµŒå…¥æ¨¡å‹: {embedding_provider.name} ({embedding_provider.model})")
        await db.refresh(embedding_provider)
        if chatbot:
            await db.refresh(chatbot)
    
    report = {"test_time": datetime.now().isoformat(), "mode": mode}
    
    # è¿è¡Œæ£€ç´¢æµ‹è¯•
    vectorstore_service = VectorStoreService()
    report["retrieval"] = await run_retrieval_test(
        test_cases, vectorstore_service, embedding_provider
    )
    
    # è¿è¡Œç­”æ¡ˆæµ‹è¯•ï¼ˆä»… full æ¨¡å¼ï¼‰
    if mode == "full" and chatbot:
        chat_service = ChatService()
        async with async_session_maker() as db:
            result = await db.execute(
                select(Chatbot)
                .where(Chatbot.id == chatbot.id)
                .options(selectinload(Chatbot.llm_provider), selectinload(Chatbot.embedding_provider))
            )
            chatbot_session = result.scalar_one()
            report["answer"] = await run_answer_test(
                test_cases, chat_service, chatbot_session, db
            )
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = output_path / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print(f"âœ… æµ‹è¯•å®Œæˆï¼æŠ¥å‘Š: {report_path}")
    print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="RAG ç³»ç»Ÿå‡†ç¡®æ€§æµ‹è¯•")
    parser.add_argument("--mode", choices=["retrieval", "full"], default="retrieval",
                        help="æµ‹è¯•æ¨¡å¼: retrieval(ä»…æ£€ç´¢) æˆ– full(å®Œæ•´)")
    parser.add_argument("--output-dir", default="./test_results", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    try:
        asyncio.run(run_tests(args.mode, args.output_dir))
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
